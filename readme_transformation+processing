"""
In the Transformation stage, cleaned data are transformed by different techniques consisting of bag of word, Word2Vec, Doc2Vec, TF-IDF, word embeddings, and Paragraph Vector-Distributed Memory (PV-DM) model.
I test the efficient of word2vec and doc2vec by creating a vector for each document then applied on a basic Logistic Regression using the sklearn library with default configuration. For the word2vec, to perform its word vector into one vector for a document, we consider several transformations as follows:
• Mean Word2Vec: compute average all word vector occurred in a single text;
• TF-IDF weighted Word2Vec: adopt TF-IDF as weights for each word embedding before taking average;
• Mean GloVe: average pre-trained GloVe word vectors from a text.
For doc2vec, we directly train doc vectors using the Paragraph Vector - Distributed Memory model [5]. We also concatenate the word2vec and doc2vec vectors to verify if having
more feature could elevate the performance. 
The source code was inherited from https://towardsdatascience.com/nlp-performance-of-differentword-embeddings-on-text-classification-de648c6262b

For the comparison, we apply three supervised machine learning algorithm: Logistic Regression, Decision Tree and Random Forest following default configuration of scikit-learn
library.

.
.
.


The experimental results appear to show the following findings in the multi-class classification task using the Yelp review dataset:
• The RNN-based model has been shown to achieve the best performance regarding Accuracy, Recall, Precision and F1-score in the classification task in overall.
• The Logistic Regression model has been standing out in predicting the review ratings in comparison with other standard machine learning-based classifiers.
• The Glove embedding approach brings better performance for the RNN-based model in predicting review rating stars, while the self-trained Word2Vec approach appears to be a better choice for machine learning-based models in predicting ratings.
• The Mean Word2Vec has been shown to be outperformed other Word2Vec-based and Doc2Vec methods.


"""
